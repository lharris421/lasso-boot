---
title: "Sampling Comparison"
author: "Logan Harris"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
---

```{r setup, child = 'web/_include/setup.rmd'}
```


# Laplace Simulation

## Coverage by Magnitude

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_laplace_100_quantile.rds")
grid::grid.draw(gobj)
```

## Overall Coverage, Width, Time, Lambda

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_laplace_100_other_quantile.rds")
grid::grid.draw(gobj)
```

## Width and Bias

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_laplace_tradref_quantile.rds")
grid::grid.draw(gobj)
```

# Ridge Comparison - High Correlation

```{r, echo = FALSE, fig.height=20, fig.width=10}
load("./web/rds/lassoboot_comparison_highcorr_100_quantile.rds")
grid::grid.draw(gobj)
```

# Traditional Comparison - Epsilon Conundrum

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_traditional_quantile.rds")
grid::grid.draw(gobj)
```

# Data Application

## whoari

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_whoari_quantile.rds")
pobj
```


## Scheetz2006

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_Scheetz2006_quantile.rds")
pobj
```


# Laplace Simulation - Bucketfill

## Coverage by Magnitude

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_laplace_100_bucketfill.rds")
grid::grid.draw(gobj)
```

## Overall Coverage, Width, Time, Lambda

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_laplace_100_other_bucketfill.rds")
grid::grid.draw(gobj)
```

## Width and Bias

```{r, echo = FALSE, fig.height=10, fig.width=10}
load("./web/rds/lassoboot_comparison_laplace_tradref_bucketfill.rds")
grid::grid.draw(gobj)
```


# Comments

How well do we want it to match the model, if that is our focus... then I think the double sided makes sense. Otherwise we could theoretically have a PE of 0 and have every bootstrap sample have shrinkage to zero and with the single side if it is always shrunken from say the positive side, then the interval would not contain zero. However, this seems like a potentially ideal behavior in the sense that the data itself suggests that the estimate is likely not zero. But, in a sense it is using additional information similar to the debiased method. I am leaning towards the two sided now. Well, maybe both are good to have and think about under the two different sides. The single sided falls more into the debias camp.

What is the coverage like if we apply penalization to the truth? Could this help us with the argument that a given interval is "ideal" under the model? Probably too simplistic, with this adjustment I would expect coverage to be wayyy to high.
