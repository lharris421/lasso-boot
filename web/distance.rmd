---
title: "Distribution to Distribution"
output:
  html_document:
    code_folding: hide
---

```{r setup, child = 'web/_include/setup.rmd'}
```

# waddR

While looking information on Wasserstein distance and potential implementations in R, I came across the package `waddR`. Here, we see an example passing in observations from two normal distributions.

```{r}
## Load library for wasserstein distnace (emperical approximation)
## devtools::install_bioc("waddR")
library(waddR)

## Generate from two normals
set.seed(24)
x <- rnorm(10000,mean=0,sd=1)
y <- rnorm(10000,mean=2,sd=1)

## Example of the wasserstein implementation
wasserstein_metric(x,y,p=2)
```

However, the implementation seems to rely heavily on the first two moments... which is great if the two distributions are normal, but worries me a bit in the case I am trying to apply it to. With a little thought, I took the conceptual idea (moving pieces of sand) and wondered why we couldn't just order the observations and then match up the ordered observations between two distributions and compute the mean absolute distance between the paired points. I.e. I am asking, "how far, on average, do we have to move the points of one distribution to create the other distribution?" What isn't yet clear to me is if this would give us the minimum amount of movement needed...

# A different approach

Note: If this idea would persist, we may wan to revert to the original definition for demonstration of the idea being linked to wasserstein distance.

The idea here is motivated by the Wasserstein distance treating each observation as a grain of sand and determing how far on average a grain must be moved in order to move one distribution to the other.

```{r}
## My idea
proxy_dist(x, y) ## Converge in the limit for normal example
```


We may then want to understand how the distributions differ from one another. Here, we will conceptualize the first distribution as being the prior and the second being the true underlying distribution of the coefficients. Of interest is how far we need to move the true distribution to match the prior.

```{r}
rlr(x, y)
```


# Comparisons

Here, I will only be adjusting the "truth", the "prior" will stay as a lapalce with rate = 1 (here as an exponential since we only care about the absolute distance).

```{r}
sz <- 10000
truth <- discrete_mixture(n = sz)
prior <- qexp(1:sz / (sz + 1), rate = 1)
proxy_dist(prior, truth)
wasserstein_metric(truth,prior,p=2)
rlr(prior, truth)
```


I really want to see if the function I created agrees with the wasserstein function.

If we set the rate to 2 for the "truth", both metrics increase.

```{r}
## Set rate to 2 for truth (both decrease)
truth <- discrete_mixture(n = sz, rate = 2)
wasserstein_metric(truth,prior,p=2)
proxy_dist(prior, truth)
rlr(prior, truth)
```

If we change pzero to be .7, as expected, both decrease.

```{r}
## Set pzero to .7 for truth (both decrease)
truth <- discrete_mixture(n = sz, rate = 1, pzero = .7)
wasserstein_metric(truth,prior,p=2)
proxy_dist(prior, truth)
rlr(prior, truth)
```

If we set the "truth" to be equal to the prior, we see that both metric produce zero.

```{r}
truth <- discrete_mixture(n = sz, rate = 1, pzero = 0)
wasserstein_metric(truth,prior,p=2)
proxy_dist(prior, truth)
rlr(prior, truth)
```

From here, we can increase the rate, and here we see the expected relation with an increase in the metrics.

```{r}
truth <- discrete_mixture(n = sz, rate = 2, pzero = 0)
wasserstein_metric(truth,prior,p=2)
proxy_dist(prior, truth)
rlr(prior, truth)
```

And if we increase the densitiy at zero, we increase the distance metrics.

```{r}
## Now add mass at zero... they both decrease
truth <- discrete_mixture(n = sz, rate = 2, pzero = .5)
wasserstein_metric(truth,prior,p=2)
proxy_dist(prior, truth)
rlr(prior, truth)
```

# Visualize the effect of rate and pzero

```{r}
sz <- 1e5
rates <- seq(.05, 1.45, by = .05)
pzeros <- seq(0, .98, by = .02)
grd <- expand.grid(rates, pzeros)

prior <- qexp(1:sz / (sz + 1), rate = 1)
dists <- apply(grd, 1, function(x) {
  truth <- discrete_mixture(n = sz, rate = x[1], pzero = x[2])
  tmp <- proxy_dist(prior, truth)
  tmp <- ifelse(tmp > 1, 1, tmp)
  return(tmp)
})
```


```{r}
df <- data.frame(rate = grd$Var1, pzero = grd$Var2, dist = dists)
ggplot() +
  geom_tile(data = df, aes(x = rate, y = pzero, fill = dist)) +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(x = "Rate", y = "Pzero", fill = "Distance") +
  theme_minimal() +
  geom_line(data = data.frame(x = c(1, 1), y = c(0, 1)), aes(x = x, y = y)) +
  geom_line(data = data.frame(x = c(.05, 1.45), y = c(0, 0)), aes(x = x, y = y))
```

This is certainly anisotropic... which is interesting.

Now let us consider the rl ratio:

```{r}
rlrs <- apply(grd, 1, function(x) {
  truth <- discrete_mixture(n = sz, rate = x[1], pzero = x[2])
  rlr(prior, truth)
})
```


```{r}
df <- data.frame(rate = grd$Var1, pzero = grd$Var2, dist = rlrs)
ggplot() +
  geom_tile(data = df, aes(x = rate, y = pzero, fill = dist)) +
  coord_cartesian(ylim = c(0, .05)) +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(x = "Rate", y = "Pzero", fill = "Distance") +
  theme_minimal() +
  geom_line(data = data.frame(x = c(1, 1), y = c(0, .11)), aes(x = x, y = y)) +
  geom_line(data = data.frame(x = c(.05, 1.45), y = c(0, 0)), aes(x = x, y = y))

```


# Priors and Truths

Set up a function that solves for the value of lambda that makes the prior as close as possible to the true data passed in. 

The ideal coverage lambda would in theory be set in a way that minimizes the distance between the truth and the prior.... well... maybe if the prior is a good one.

Well... first, maybe I should see if this is even behaving reasonably.

```{r}
## rate = 1
## sig = 1
## n = p = 100
## prior => lambda of 1/100

## Now draw the truth from the prior
truth <- discrete_mixture(pzero = 0, n = 100)

## Looks pretty solid to me
optimize(f = met, c(.0001, 10), truth = truth, n = 100) ## 1/100 = .1
```

Then, we can use this to try and set a value for lambda:

```{r}
truth <- c(1,-1,0.5,-0.5,0.5,-0.5, rep(0, 54))
optimize(f = met, c(1e-4, 1e4), truth = truth, n = 100)
```

Well.... this isn't going to work...
